Analyse expérimentale de l'impact du désordre sur les performances des algorithmes de tri.

Ce projet universitaire réalisé dans le cadre de la Licence Informatique à l'Université de Caen Normandie vise à comprendre comment la quantité et la répartition du désordre influencent l'efficacité des algorithmes de tri en termes de comparaisons, d'échanges et de temps d'exécution.

1. Générateurs de données :

    Distribution uniforme : Toutes les valeurs ont la même probabilité d'apparaître
    Distribution normale : Valeurs centrées autour d'une moyenne avec un écart-type
    Désordre aléatoire : Échanges aléatoires entre positions quelconques
    Désordre local : Échanges uniquement entre éléments voisins

2. Générateur de séries :

    Schéma répétitif : Blocs de valeurs identiques (ex: 1 1 1 2 2 2)
    Schéma séquentiel : Répétition cyclique d'une séquence (ex: 1 2 3 1 2 3)
    Schéma mélangé : Répartition aléatoire des valeurs
    Calcul d'entropie : Mesure du niveau de désorganisation des données


